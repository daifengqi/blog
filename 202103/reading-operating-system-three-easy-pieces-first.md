# 阅读：操作系统导论（上）

# Reading: Operating Systems: Three Easy Pieces (First Half)

## 2021 年 3 月 1 日

## Mar 1 2021

---

**超越库**

操作系统从最初的标准库发展到现在这个样子，经历一个阶段。将原本调用库的过程分离为过程调用（procedure call）和系统调用（system call），后者是前者权限的提升（通常是硬件特权级别）。这样做是出于安全的考虑，过程调用交给用户，系统调用在操作系统内部发生，确保用户的操作不会损害系统。

举例来说，用户程序通常不能发起对磁盘的 I/O 请求，不能访问任何物理内存页或在网络上发送数据包。用户通过 trap（一个特殊硬件指令），将控制权转移给操作系统预先制定的处理程序（trap handler），操作系统在特权级别下执行指令，再通过特殊的返回指令（return-from-trap）将控制权交还给应用程序，同时切换特权级别。

**进程**

进程的简单定义是正在运行的程序，或是正在运行的程序的抽象。它由两个组成部分：内存和寄存器。内存是进程的执行指令和数据存放的地方，寄存器则是更小更快的储存，通常一个寄存器只能寄存单个或极小的数据和指令。进程的运行过程就是通过不断在很多个寄存器里放入和取出数据和指令。<u>当一个程序从磁盘读入内存开始运行时，才能被称为进程。</u>

请注意，有一些非常特殊的寄存器构成了机器状态的一部分。例如，程序计数器（Program Counter，PC）（有时称为指令指针，Instruction Pointer 或 IP）告诉我们程序当前正在执行哪个指令；类似地，栈指针（stack pointer）和相关的帧指针（frame pointer）用于管理函数参数栈、局部变量和返回地址。

操作系统必须提供关于进程的 API：创建、销毁、暂停、或其它控制手段，以及能够返回进程的当前状态。

进程通常有三种状态：运行、就绪和阻塞。就绪状态下的程序随时可以运行，而阻塞状态一般是在等待 I/O 操作。操作系统调度多个程序的运行，就是在不断切换这些程序的状态。

进程控制块、或进程列表是一种数据结构，操作系统通过它来跟踪进程的信息。比如进程的上下文（context），进程上下文是所有寄存器状态的集合，当进程切换时，被切换的进程需要把当前上下文保存当内存中的某个位置，以便在切回时取出。

**Unix 关于进程的关键 API**

<u>Unix 有三个关于进程的关键 API，fork()、wait()和 exec()（各种变体）。</u>历史经验表明通过这三个函数来管理进程是最佳实践。举例来说，对于一个 shell 程序，它允许用户输入某些代码作为程序，shell 程序自身先运行，呈现出画面，然后调用 fork()创建新的进程，在 exec()中传入需要执行的程序及参数，之后调用 wait()，在输入程序执行结束后，shell 会向屏幕输出提示符。fork，exec，wait 三者分离的思想使得进程可以在三者前后或之间插入自己要执行的代码片段，这使得实现某些功能非常方便，这样的做法也被采纳为最佳实践。

**单个进程执行步骤**

- [ ] 在进程列表上创建条目
- [ ] 为程序分配内存
- [ ] 将程序加载到内存中
- [ ] 根据 argc/argv 设置程序栈
- [ ] 清除寄存器
- [ ] 执行 call main()方法
- [ ] 找到入口点并跳转到执行 main()【程序】
- [ ] 从 main 中执行 return【程序】
- [ ] 释放进程的内存
- [ ] 将进程从进程列表中清除

**进程之间如何切换？**

答案很简单，许多年前构建计算机系统的许多人都发现了：时钟中断（timer interrupt）。时钟可以设置为每隔很小的时间进行一次中断，比如几毫秒，这个时候，正在运行的程序终止，由操作系统预先配置的中断处理程序来告诉 CPU，继续运行什么。此时，操作系统重新获得 CPU 的控制权，因此可以做它想做的事：停止当前进程，并启动另一个进程。<u>操作系统始终保证能够获得 CPU 的控制权。</u>

在发生中断时，在硬件层面需要为当前进程保存状态，以便能够在之后切换回当前程序（通过陷阱返回指令恢复）。与进行系统调用时陷入内核的行为相似，各种寄存器的值会被保存下来。

<u>上下文切换</u>在概念上很简单：操作系统要做的就是为当前正在执行的进程保存一些寄存器的值（例如，到它的内核栈），并为即将执行的进程恢复一些寄存器的值（从它的内核栈）。

**寄存器的保存和恢复**

分为两种情况。

1. 时钟中断：由硬件设置隐式保存。
2. 系统调用：由 OS 明确地保存。

**重启是优秀的行为**

重启是非常有用的，它能让操作系统和软件都回到已知的状态，并且可以回收旧的或泄漏的资源。因此，在一些大规模集群中，系统会定期重启一些机器，重置它们并因此获得以上好处，这并不少见。

**系统调度：由浅入深**

<u>只考虑周转时间的算法：</u>

1. 最简单的方案是先进先出（FIFO），即总是先执行先到达的任务，待任务执行完成后继续执行下一个任务，这个方案最容易实现，但是它有许多缺点。
2. 第二个方案是最短任务优先（SJF，Shortest Job First），将等待中的进程中完成时间最快的优先执行。SJF 是非抢占式的（non-preemptive），这意味着下一个进程的执行总是要等待上一个进程执行结束。但是，现代操作系统中的系统调度方案几乎都是抢占式的。
3. 向 SJF 添加抢占，得到一种新的方案，称为最短完成时间优先（Shortest Time-to-Completion First，STCF）。每当新工作进入系统时，它就会确定正在执行的进程的剩余工作和新工作中，谁的执行时间最少，然后调度该工作开始执行。

只考虑周转时间的算法是不好的，因为这可能会导致进程的响应时间过久，这两者需要平衡。比如当你在终端输入时，不得不等待 10 秒才能看到输出结果，这是非常糟糕的。因此，下一个问题是：如何构建对响应时间敏感的调度程序？答案是使用轮转技术，即每个程序都运行一定的时间片。<u>操作系统必须机灵地设置时间片的长度，太短虽然会提高响应速度，但会引入上下文切换的成本，太长则反之。</u>

在带有 I/O 的进程调度中，我们要尽可能使得任务重叠进行，比如在一项任务等待 I/O 时，就让 CPU 执行另一个任务，这就是现代单线程语言中<u>异步</u>的思想。（单线程，可以类比单个 CPU，它们的共同点是只能同时执行一个任务）。

**现代操作系统的调度方法：多级反馈队列（MLFQ）**

- 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。
- 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。

以上两点是最基础的。

- 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
- 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。
- 规则 4b：如果工作在其时间片以内主动释放 CPU，则优先级不变。

以上三个规则带来了这些好处：短周转时间的进程可以立刻被执行（比如打字），而且 I/O 密集型操作会因为主动释放 CPU 而不受到降低优先级的惩罚。

问题是：长进程可能会“饥饿”（进程始终被短进程占用），而且用户可以在程序中加入无关 I/O 操作以欺骗操作系统，从而获得不公平的待遇，优先级始终不会被下调。

- 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。

加入这个规则，保证了长进程不会被饿死，它始终会在最高优先级被轮转执行。

- 规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次 CPU），就降低其优先级（移入低一级队列）。

让规则 4 覆盖 4a 和 4b，以防止程序愚弄调度系统。这样一来不管它如何释放 CPU，最终总会被降级。

关于 MLFQ 调度算法还有一些问题。其中一个大问题是如何配置一个调度程序，例如，配置多少队列？每一层队列的时间片配置多大？为了避免饥饿问题以及进程行为改变，应该多久提升一次进程的优先级？这些问题都没有显而易见的答案，因此只有利用对工作负载的经验，以及后续对调度程序的调优，才会导致令人满意的平衡。

**引入随机性的概率调度思想：彩票调度或比例份额**

每隔一定时间进行一次抽奖，抽中哪个进程，CPU 就执行哪个进程，并且为高优先级的程序设置高概率。对于彩票调度，有三种机制：

- 彩票货币（ticket currency）：让不同用户自行分配进程被选中的概率。
- 彩票转让（ticket transfer）：运行时改变概率，这在客户端-服务端模式很有用，当客户端等待服务端返回值时，它可以将自己的概率转让给服务端，以提高速度。
- 彩票通胀（ticket inflation）：在运行时提高或降低概率。

彩票调度的实现非常简单，只需要一个链表，操作系统首先在总彩票个数中选择一个随机数，然后便利链表，当这个数字在某个进程的区间内时，就执行它一定的时间片；然后操作系统从表头开始，反复抽数，然后找到需要执行的进程。

彩票调度通过步长来分配彩票数：系统中的每个工作都有自己的步长，这个值与票数值成反比。每次进程运行后，我们会让它的计数器增加它的步长，记录它的总体进展。

**多处理器调度的三个问题**

多处理器是指有多个 CPU，每个 CPU 有自己的缓存，而所有 CPU 共用一个内存。

- 缓存一致性（解决方法：基于总线窥探的内存访问监控，一旦指定缓存更新，则删除本地副本。）
- 原子性、锁和性能问题
- 缓存亲和度（在同一个 CPU 上运行之前的程序，有更高的缓存亲和度，所以会更快，反之会变慢。）

**多处理器调度：单队列和多队列**

- 单队列调度

优势：简单，将原有的策略用在多个 CPU 上，负载均衡较好。

缺点：锁的性能问题、缓存亲和度问题。

- 多队列调度

优势：解决了以上问题。

缺点：负载不均。

<u>如何应对负载不均？</u>最明显的答案是让工作移动，这种技术我们称为迁移（migration）。通过工作的跨 CPU 迁移，可以真正实现负载均衡。一个基本的方法是采用一种技术，名为工作窃取（work stealing）。工作量较少的 CPU 不断从工作量多，即队列中有较多任务的 CPU 中偷取进程过来。问题在于，如果检查间隔时间短，会带来额外的开销，过长也解决不了严重的负载不均，找到合适的阈值仍然是黑魔法，这在系统策略设计中很常见。

**小结：学习操作系统调度的益处**

我非常喜欢操控调度程序的概念。我下次在亚马逊的 EC2 服务上运行一项工作时，看起来这可能是需要考虑的事情。也许我可以从其他一些毫无戒心的（更重要的是，对操作系统一无所知的）客户那里窃取一些时间周期。

**关于内存的时分共享**

一种实现时分共享的方法，是让一个进程单独占用全部内存，运行一小段时间，然后停止它，并将它所有的状态信息保存在磁盘上，之后加载其他进程的状态信息，这就实现了某种比较粗糙的机器共享

**进程的地址空间**

一个进程的地址空间包含运行的程序的所有内存状态。比如：

- 程序的代码（code，指令）。
- 栈（stack）来保存当前的函数调用信息，分配空间给局部变量，传递参数和函数返回值（向上增长）。
- 堆（heap）用于管理动态分配的、用户管理的内存（向下增长）。
- 还有其他的东西（例如，静态初始化的变量）。

当你在语言里声明一个变量时，就是在自动获取栈内存，而在 C 里显示声明堆内存需要用到 malloc()之类的函数，之后通过 free()来释放它。在除了 C/C++的语言里，内存管理是自动的，会有专门的垃圾收集算法和进程来做这件事情。另外，请注意 malloc()不是一个系统调用，它只是建立在一些系统调用之上的库函数。

**操作系统一开始的样子**

早期的操作系统并没有什么抽象，机器的内存只分为两块，操作系统和用户程序，操作系统是一个函数库，且作为一个进程运行，剩下的内存由用户程序全部占据。

**多道程序和时分共享**

操作系统应该能同时进行多道进程。在运行一个进程时，其它进程在队列中等待。在进程切换时，将进程的全部信息从寄存器保存到内存而不是磁盘中，因为磁盘 I/O 太缓慢了。这种技术称为时分共享。当多个程序同时驻留在内存中时，我们不希望一个进程可以读取其它进程的内容，这使保护（protection）成为重要问题。

**虚拟地址**

任何高级语言打印的地址都是虚拟地址，操作系统不能让用户渗入到真实的物理地址。操作系统使用一个空闲列表记录当前没有使用的物理地址的范围。

**地址转换**

从虚拟地址转换到真实地址的公式是加上一个基址（base），这个过程称为重定位（relocation），基于硬件的重定位称为动态重定位，相较于基于加载软件（loader）的静态重定位，它的优点是提供保护，并且可以在运行时方便地改变地址空间。在动态重定位的过程中，会有一个界限（bound）寄存器来限制进程地址空间的范围。

动态重定位的问题是，进程的堆和栈之间有大量的空间没有被使用，这造成了浪费，这种浪费通常称为内部碎片（internal fragmentation）。通过将基址加界限的概念泛化，得到分段（segmentation）的方式来解决内存碎片的问题。

**基址与界限**

基址寄存器与界限寄存器一般存在于 CPU 芯片中的内存管理单元（Memory Management Unit，MMU）。

**操作系统与内存**

1. 在进程创建时，操作系统为进程的地址空间找到内存空间。这对操作系统来说很容易。它可以把整个物理内存看作一组槽块，标记了空闲或已用。当新进程创建时，操作系统检索这个数据结构（常被称为空闲列表，free list），为新地址空间找到位置，并将其标记为已用。
2. 在进程终止时（正常退出，或因行为不端被强制终止），操作系统回收它的所有内存，将这些内存放回到空闲列表，并根据需要清除相关的数据结构。
3. 在上下文切换时，操作系统也必须执行一些额外的操作。每个 CPU 毕竟只有一个基址寄存器和一个界限寄存器，但对于每个运行的程序，它们的值都不同，因为每个程序被加载到内存中不同的物理地址。因此，在切换进程时，操作系统必须保存和恢复基础和界限寄存器。具体来说，当操作系统决定中止当前的运行进程时，它必须将当前基址和界限寄存器中的内容保存在内存中，放在某种每个进程都有的结构中，如进程结构（process structure）或进程控制块（Process Control Block，PCB）中。类似地，当操作系统恢复执行某个进程时（或第一次执行），也必须给基址和界限寄存器设置正确的值。
4. 操作系统必须提供异常处理程序（exception handler），或要一些调用的函数，像上面提到的那样。操作系统在启动时加载这些处理程序（通过特权命令）。例如，当一个进程试图越界访问内存时，CPU 会触发异常。在这种异常产生时，操作系统必须准备采取行动。通常操作系统会做出充满敌意的反应：终止错误进程。

**分段（segment）**

分段的思想很简单，就是不只是让每个 CPU 拥有一个基址寄存器与界限寄存器，而是多个。每一对基址/界限寄存器存有一个段的内容，比如代码段、数据段等，段错误指的是在支持分段的机器上发生了非法的内存访问。在显示的段访问中，我们只需要在虚拟地址的开头加几个二进制比特来标志段，比如 00 代表代码段，01 代表堆地址。由于栈是反向增长的，我们还需要用一个位来表示段的增长放心。还可以提供一些位来增加其它功能，比如保护位（protection bit）用作标志段的读写/共享权限。

新的地址空间被创建时，操作系统需要在物理内存中为它的段找到空间。进程地址空间堆和栈之间未使用的区域称为内部碎片，不同进程地址空间的间隙称为外部碎片。

**空间的分割与合并：空闲列表**

申请内存：通过遍历链表，找到一块空闲的满足大小的，分割为两块，一块标记为使用，另一块保持标记为空闲。在遍历的过程中会合并两块连续的标记为空闲的列表。具体的算法有很多：首次匹配、下次匹配、最优匹配、最差匹配等。

释放内存：将整个标记为使用的内存块标记为空闲，然后与相邻的空闲列表合并。

分离空闲列表（为经常申请某个大小的程序单独管理一个空闲列表）和伙伴系统（递归二分，易于合并）是常用的空间管理的算法。

**分段与分页（page）**

有时候人们会说，操作系统有两种方法，来解决大多数空间管理问题。

- 第一种：将空间分割成不同长度的分片，就像虚拟内存管理中的分段。遗憾的是，这个解决方法存在固有的问题。具体来说，将空间切成不同长度的分片以后，空间本身会碎片化（fragmented），随着时间推移，分配内存会变得比较困难。
- 第二种：将空间分割成固定长度的分片。在虚拟内存中，我们称这种思想为分页。分页不是将一个进程的地址空间分割成几个不同长度的逻辑段（即代码、堆、段），而是分割成固定大小的单元，每个单元称为一页。相应地，我们把物理内存看成是定长槽块的阵列，叫作页帧（page frame）。每个这样的页帧包含一个虚拟内存页。

**页表**

为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表（page table）。页表实现了从虚拟地址到物理地址的映射。页表带来了额外的性能开销，因为每次进程需要访问内存（地址空间）时，都需要先访问页表，再能访问实际的物理地址。

硬件必须知道当前正在运行的进程的页表的位置，这通常通过页表基址寄存器（page-table base register）得到，它包含页表的起始位置的物理地址。

页表中除了保存从虚拟地址（键或索引）到物理地址（值）的映射以外，还可以有多个位，比如，x86 架构包含一个存在位（P，表示该页是在物理存储器还是在磁盘上），确定是否允许写入该页面的读/写位（R/W）确定用户模式进程是否可以访问该页面的用户/超级用户位（U/S），有几位（PWT、PCD、PAT 和 G）确定硬件缓存如何为这些页面工作，一个访问位（A，有时用于追踪页是否被访问，也用于确定哪些页很受欢迎。）和一个脏位（D，表明页面被带入内存后是否被修改过。），最后是页帧号（PFN）本身

**分页的硬件：转移缓存旁路（Translation lookaside buffer，TLB）**

TLB 是一种硬件缓存（cache），对每次内存访问，硬件先检查 TLB，看看其中是否有期望的转换映射，如果有，就完成转换（很快），否则再访问页表（其中有全部的转换映射）。

通过增加一个小的、芯片内的 TLB 作为地址转换的缓存，大多数内存引用就不用访问内存中的页表了。

在精简指令集计算机（Reduced-Instruction SetComputer，RISC）中，发生 TLB 未命中时，硬件系统会抛出一个异常，这会暂停当前的指令流，将特权级提升至内核模式，跳转至陷阱处理程序（trap handler）。这个陷阱处理程序是操作系统的一段代码，查找页表中的转换映射，然后用特别的“特权”指令更新 TLB，并从陷阱返回。此时，硬件会重试该指令（导致 TLB 命中）。

页表和 TLB 都是每个进程特有的，在上下文切换时需要修改。为了减少这种开销，一些系统增加了硬件支持，实现跨上下文切换的 TLB 共享。比如有的系统在 TLB 中添加了一个地址空间标识符（Address Space Identifier，ASID）。有了地址空间标识符，TLB 可以同时缓存不同进程的地址空间映射。如果两个进程共享同一物理页（例如代码段的页），TLB 就不需要切换。

**TLB 替换策略**

TLB 和其他缓存一样，还有一个问题要考虑，即缓存替换（cache replacement）。具体来说，向 TLB 中插入新项时，会替换（replace）一个旧项，这样问题就来了：应该替换那一个？目标当然是减小 TLB 未命中率（或提高命中率），从而改进性能。

最简单的策略是 LRU，是替换最近最少使用（least-recently-used，LRU）的项。

**TLB 与 DBMS**

TLB 不能满足所有的程序需求。具体来说，如果一个程序短时间内访问的页数超过了 TLB 中的页数，就会产生大量的 TLB 未命中，运行速度就会变慢。解决这个问题的一种方案是支持更大的页，把关键数据结构放在程序地址空间的某些区域，这些区域被映射到更大的页，使 TLB 的有效覆盖率增加。<u>对更大页的支持通常被数据库管理系统（Database Management System，DBMS）这样的程序利用，它们的数据结构比较大，而且是随机访问。</u>

**现代操作系统一：分段分页**

在硬件中，假设有 3 个基址/界限对，代码、堆和栈各一个。当进程正在运行时，每个段的基址寄存器都包含该段的线性页表的物理地址（即先由段基址寄存器映射到页表地址）。因此，系统中的每个进程现在都有 3 个与其关联的页表（每个段有 1 个）。在上下文切换时，必须更改这些寄存器，以反映新运行进程的页表的位置。

**现代操作系统二：多级页表**

为多级页表（multi-level page table）将线性页表变成了类似树的东西。多级页表通过层层递进，不断通过目录找到最终要用的页表项，避免了大量无效位的标记。这是一种时空折中的策略，虽然在空间上，多级页表减少了很多，但是访问缓存或内存的次数都会这样的多级结构而增多。

注意，当使用内存受限制时，小结构的多级页表是有意义的。而较多内存，并且工作负载主动使用大量内存页的系统中，用更大的页表来加速 TLB 未命中处理，可能是正确的选择。

**硬盘、交换和页错误**

为了处理页错误，首先，操作系统必须为将要换入的页找到一个物理帧，如果没有这样的物理帧，我们将等待交换算法运行，从内存中踢出一些页，释放帧供这里使用。在获得物理帧后，处理程序发出 I/O 请求从交换空间读取页。最后，当这个慢操作完成时，操作系统更新页表并重试指令。重试将导致 TLB 未命中，然后再一次重试时，TLB 命中，此时硬件将能够访问所需的值。

操作系统为了保证始终有足够的空闲内存，会设置高水位线（High Watermark，HW）和低水位线（Low Watermark，LW），来帮助决定何时从内存中清除页。当操作系统发现有少于 LW 个页可用时，后台负责释放内存的线程会开始运行，直到有 HW 个可用的物理页。这个后台线程有时称为交换守护进程（swap daemon）或页守护进程（page daemon），它每次启动时都为操作系统释放一些内存，然后休眠。

进程要从磁盘获取数据，就需要在页表结构中需要添加额外信息，比如增加一个存在位（present bit，或者其他类似机制），告诉我们页是不是在内存中。如果不存在，则操作系统页错误处理程序（page-fault handler）会运行以处理页错误（page fault），从而将需要的页从硬盘读取到内存，可能还需要先换出内存中的一些页，为即将换入的页腾出空间。

这些操作对进程都是透明的，它只是访问自己私有的、连续的虚拟内存。在后台，物理页被放置在物理内存中的任意（非连续）位置，有时它们甚至不在内存中，需要从硬盘取回。

**交换策略**

- 最优策略：踢出最远访问的页，但这种策略无法实现，因为操作系统并不知道访问未来的访问顺序。

- 最简单策略：FIFO、随机。

- 优化一些的策略：LRU，利用两个历史信息，频率（frequency）和近期性（recency）。频率表示，如果一个页被访问了很多次，也许它不应该被替换，因为它显然更有价值。页更常用的属性是访问的近期性，越近被访问过的页，也许再次访问的可能性也就越大。

**近似 LRU 策略的具体实现**

操作系统如何利用使用位来实现近似 LRU？可以有很多方法，有一个简单的方法称作时钟算法（clock algorithm）。想象一下，系统中的所有页都放在一个循环列表中。时钟指针（clock hand）开始时指向某个特定的页（哪个页不重要）。当必须进行页替换时，操作系统检查当前指向的页 P 的使用位是 1 还是 0。如果是 1，则意味着页面 P 最近被使用，因此不适合被替换。然后，P 的使用位设置为 0，时钟指针递增到下一页（P+1）。该算法一直持续到找到一个使用位为 0 的页，使用位为 0 意味着这个页最近没有被使用过（在最坏的情况下，所有的页都已经被使用了，那么就将所有页的使用位都设置为 0）。

还可以加入脏页的特性，硬件可以包括一个修改位（modified bit，又名脏位，dirty bit）。每次写入页时都会设置此位，因此可以将其合并到页面替换算法中，即扫描既未使用又干净的页先踢出。无法找到这种页时，再查找脏的未使用页面，等等。

**取页与写入的其它算法**

对于大多数页而言，操作系统只是使用<u>按需分页（demand paging）</u>，这意味着操作系统在页被访问时将页载入内存中，“按需”即可。当然，操作系统可能会猜测一个页面即将被使用，从而提前载入。这种行为被称为<u>预取</u>，只有在有合理的成功机会时才应该这样做。例如，一些系统将假设如果代码页 P 被载入内存，那么代码页 P+1 很可能很快被访问，因此也应该被载入内存。
另一个策略决定了操作系统如何将页面写入磁盘。当然，它们可以简单地一次写出一个。然而，许多系统会在内存中收集一些待完成写入，并以一种（更高效）的写入方式将它们写入硬盘。这种行为通常称为<u>聚集（clustering）写入</u>或分组写入（grouping），这样做有效是因为硬盘驱动器的性质，执行单次大的写操作，比许多小的写操作更有效。

**抖动**

当内存就是被超额请求时，操作系统应该做什么，这组正在运行的进程的内存需求是否超出了可用物理内存？在这种情况下，系统将不断地进行换页，这种情况有时被称为抖动。解决抖动的办法是强制杀死某些进程。

**内存小结**

- 操作系统用 CPU 来调度进程，用内存来储存进程。

- 对于每一个进程，操作系统实际上是先访问虚拟内存，再访问物理内存。这样做的好处主要有三点，一是保护了内存的独立性，二是提高了内存的使用效率，直接使用物理内存容易产生内部碎片，三是方便在运行的时候动态地修改地址。
- 操作系统使用分段和分页的技术来控制进程的访问，两者各有优缺点，在有些时候需要结合使用。分段和分页都是为了解决碎片问题，分段可以让某些段在不同进程中复用，减少切换开销，由于不同进程的段大小各不相同，在分配和释放的时候难以管理。使用分页方法可以灵活处理碎片，分页方法是通过页表将虚拟地址映射到物理地址的。
- 操作系统通过一个叫 TLB 的硬件管理页表的访问。TLB 是一个超快的缓存，进程每次需要查找物理地址时，首先访问 TLB，如果没有的话再从内存更新到 TLB。使用 TLB 可以有效加速进程对数据的访问。
- 多级页表的好处是减少了页表无效位的储存，因此极大地缩小了页表的大小。从单个线性页表到多级页表的优化思想类似于从数组到哈希表的优化。
- 进程使用内存的时候，有时候需要和磁盘交换数据，这就需要页交换策略。最典型的页交换策略是 LRU，一种近似 LRU 的具体实现是通过一个标记位来记录每一页的使用与否，每次换出时都换出未使用的页，待到所有页都标记位使用时，再将标记位全部清零，如此循环。

**新抽象：线程（thread）**

经典观点是一个程序只有一个执行点（一个程序计数器，用来存放要执行的指令），但多线程（multi-threaded）程序会有多个执行点（多个程序计数器，每个都用于取指令和执行）。每个线程类似于独立的轻量进程，只有一点区别：它们共享地址空间，从而能够访问相同的数据

单个线程的状态与进程状态非常类似。线程有一个程序计数器（PC），记录程序从哪里获取指令。每个线程有自己的一组用于计算的寄存器。所以，如果有两个线程运行在一个处理器上，从运行一个线程（T1）切换到另一个线程（T2）时，必定发生上下文切换（contextswitch）。线程之间的上下文切换类似于进程间的上下文切换。对于进程，我们将状态保存到进程控制块（Process Control Block，PCB）。现在，我们需要一个或多个线程控制块（Thread Control Block，TCB），保存每个线程的状态。但是，与进程相比，线程之间的上下文切换有一点主要区别：地址空间保持不变（即不需要切换当前使用的页表）。

多个线程共享堆，有各自的栈，这些栈在都在相对于堆的低地址位置，向上增长，各自占用一块空间。因此，线程局部变量应该是线程私有的，其他线程不应该访问。

**并发的关键概念**

竞态条件（race condition）：结果取决于代码的不可控执行顺序。

临界区（critical section）：访问共享资源的代码片段。

互斥（mutual exclusion）：如果一个线程在临界区内执行，其他线程将被阻止进入临界区。

原子性（atomically）：作为一个单元全部执行，或全部不执行。另外，将许多行为组合为单个原子动作称为事务（transaction）。

**锁**

我们希望原子式执行一系列指令，但由于单处理器上的中断，我们做不到。锁（lock），直接解决这一问题。程序员在源代码中加锁，放在临界区周围，保证临界区能够像单条原子指令一样执行。锁有两种状态：可用的和被占用的。

评价一个锁的好坏有三点，从低到高为：

1. 提供互斥的能力；
2. 公平性，级不会产生饥饿；
3. 性能友好；

**锁的实现方案**

最简单的方案是，在加锁的临界区关闭中断。这种实现的唯一优点就是简单，缺点可太多了：对线程的信任问题、多处理器无法实现、中断丢失导致严重的系统问题、效率低下，因为现代 CPU 对于关闭和打开中断的代码执行得较慢。

现代 CPU 一般提供锁的硬件支持：

- 测试并设置指令（test-and-set instruction）。这一指令可以通过互斥量（mutex）简单设置一个自旋锁（spin lock）。然而，在单处理器上，需要抢占式的调度器（preemptive scheduler，即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

- 比较并交换指令（SPARC 系统中是 compare-and-swap，x86 系统是 compare-and-exchange）：比较并交换的基本思路是检测值是否和期望值相等；如果是，更新所指的值为新值。否则，什么也不做。比较并交换指令也可以简单地实现自旋锁。
- 获取并增加（fetch-and-add）指令：它能原子地返回特定地址的旧值，并且让该值自增。该指令也可以实现锁，通过一个标记号和一个顺位号，每次线程进入临界区时，就让标记号加一作为它的进入顺位号。相比前两个指令，该指令也确保了公平性，即只要一个线程拿到了它的顺位号，就一定可以进入临界区。

**更高性能的锁**

- 解决自旋过多：让出来。
- 设置休眠：将测试并设置和等待队列结合，实现了一个更高性能的锁，通过队列来控制谁会获得锁，避免饿死。
- 两阶段锁：先尝试自旋一段时间，再休眠。
